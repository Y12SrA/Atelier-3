{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134ef9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "     ---------------------------------------- 0.0/176.4 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 30.7/176.4 kB 445.2 kB/s eta 0:00:01\n",
      "     --------------- --------------------- 71.7/176.4 kB 491.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 176.4/176.4 kB 971.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pytorch-transformers) (1.24.3)\n",
      "Collecting boto3 (from pytorch-transformers)\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/0a/8e/fab7dbeb7251d8ff2f63812f3fdf57eef87d0a37e1422b31cb6b72082dd4/boto3-1.34.2-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.34.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pytorch-transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2022.7.9)\n",
      "Collecting sentencepiece (from pytorch-transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "     ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n",
      "     ----------- -------------------------- 286.7/977.5 kB 5.9 MB/s eta 0:00:01\n",
      "     -------------------------- ----------- 675.8/977.5 kB 7.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/977.5 kB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 977.5/977.5 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting sacremoses (from pytorch-transformers)\n",
      "  Obtaining dependency information for sacremoses from https://files.pythonhosted.org/packages/0b/f0/89ee2bc9da434bd78464f288fdb346bc2932f2ee80a90b2a4bbbac262c74/sacremoses-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (2023.4.0)\n",
      "Collecting botocore<1.35.0,>=1.34.2 (from boto3->pytorch-transformers)\n",
      "  Obtaining dependency information for botocore<1.35.0,>=1.34.2 from https://files.pythonhosted.org/packages/b7/52/541fbf07388a44693941c126d9a356687da749ceb2a03ad3f2d53735ff2d/botocore-1.34.2-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.34.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Collecting s3transfer<0.10.0,>=0.9.0 (from boto3->pytorch-transformers)\n",
      "  Obtaining dependency information for s3transfer<0.10.0,>=0.9.0 from https://files.pythonhosted.org/packages/fd/fb/46eda754e80fa2efd82981e37cd75cabbecef71df63843e6e94e12fae9db/s3transfer-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading s3transfer-0.9.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2023.11.17)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->pytorch-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sacremoses->pytorch-transformers) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm->pytorch-transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.2->boto3->pytorch-transformers) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.2->boto3->pytorch-transformers) (1.16.0)\n",
      "Downloading boto3-1.34.2-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.3/139.3 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "   ---------------------------------------- 0.0/897.5 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 276.5/897.5 kB 8.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 655.4/897.5 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  890.9/897.5 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 897.5/897.5 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading botocore-1.34.2-py3-none-any.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/11.8 MB 12.9 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.7/11.8 MB 9.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/11.8 MB 9.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/11.8 MB 7.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/11.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.9/11.8 MB 7.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.2/11.8 MB 6.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.8 MB 7.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.8/11.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/11.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/11.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.6/11.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.9/11.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.1/11.8 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.1/11.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.8 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.8 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.6/11.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.9/11.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.1/11.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.4/11.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/11.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/11.8 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/11.8 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.8 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.5/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.7/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.0/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.2/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.5/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.8/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.3/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.6/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.8/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.1/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/11.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.5/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.8/11.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.1/11.8 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.4/11.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.7/11.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.9.0-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.0/82.0 kB ? eta 0:00:00\n",
      "Installing collected packages: sentencepiece, sacremoses, botocore, s3transfer, boto3, pytorch-transformers\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.76\n",
      "    Uninstalling botocore-1.29.76:\n",
      "      Successfully uninstalled botocore-1.29.76\n",
      "Successfully installed boto3-1.34.2 botocore-1.34.2 pytorch-transformers-1.2.0 s3transfer-0.9.0 sacremoses-0.1.1 sentencepiece-0.1.99\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.34.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad63fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f5e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tokenizer.encode(self.data[idx]))\n",
    "\n",
    "# Instantiate the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Example of a placeholder dataset\n",
    "custom_dataset = [\"Un jour\"] * 100\n",
    "\n",
    "# Define the model configuration\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tuned_model = GPT2LMHeadModel(config=config)\n",
    "fine_tuned_model.train()\n",
    "\n",
    "train_dataset = CustomDataset(custom_dataset, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Example fine-tuning loop\n",
    "optimizer = torch.optim.AdamW(fine_tuned_model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):  \n",
    "    for batch in train_dataloader:\n",
    "        inputs = batch \n",
    "        labels = batch  \n",
    "\n",
    "        outputs = fine_tuned_model(inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f0806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "In a galaxy far, far away jour jour Weed jour Lucius jour Fishing jour wars jour Eli jouranother jour 395 jour bipolar jour phil jour Kirk jour Re jour neurons jour Kra jour Ud jour 1941 jourDERR jour legitim jourIGHT jourery jouristrate jour apple jour Novel jour visibly jour peacefully jour DeV jourandi jour Foundation jour Invention jour dart jour strongly jour pornographic jour Fil jour transsexual jour compares jour furnished jour partic jourLee jour Texture jourakings jourtab jour progress journative jour Ec jour decade jour assessments jourWC jourFore jour Paint jour yo jour Greenwich jour gonna jour Avengers jour Recommended jour mills jour598 jourband jourHowever jourmom jour illustrious jourparts jour orderly jour scriptures jour 420 jour alleviate jourHyd jour systematically jourAAAAAAAA jourwana jour COUR jour ES jourQU jour spontaneous jourutes jourai jour ambiguity jouricon jourseless jour walking jour convicted jour product jour Abs jour Economy jour Rouse jourExper jour cruc jour resurg jourjah jour Flame jour cherish jour facts jour sexy jour Freem jour resentment jourJSON jour white jourbred\n"
     ]
    }
   ],
   "source": [
    "def generate_paragraph(prompt, model, tokenizer, max_length=200, temperature=0.8):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"In a galaxy far, far away\"\n",
    "\n",
    "# Generate a new paragraph\n",
    "generated_paragraph = generate_paragraph(prompt, fine_tuned_model, tokenizer)\n",
    "print(generated_paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beefbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
